{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "sourceId": 8074461,
     "sourceType": "datasetVersion",
     "datasetId": 4764891
    },
    {
     "sourceId": 8084878,
     "sourceType": "datasetVersion",
     "datasetId": 4772419
    },
    {
     "sourceId": 8140896,
     "sourceType": "datasetVersion",
     "datasetId": 4809939
    }
   ],
   "dockerImageVersionId": 30683,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": false
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchmetrics"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T21:35:36.240164900Z",
     "start_time": "2024-04-17T21:35:32.482004100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class GlauDataset(Dataset):\n",
    "    def __init__(self, is_train, transform=None):\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        \n",
    "        csv_file = '/fast/yangz16/glaucoma/archive/path_specified_label_SIMPLIFIED.csv'\n",
    "        df = pd.read_csv(csv_file)\n",
    "        ids = df['Eye ID'].tolist()\n",
    "        labels = df['Final Label'].tolist()\n",
    "        ids = [_.split('/')[-1] for _ in ids]\n",
    "\n",
    "        pos_cases = []\n",
    "        neg_cases = []\n",
    "        for id, lab in zip(ids, labels):\n",
    "            if lab == 1:\n",
    "                pos_cases.append((id, lab))\n",
    "            elif lab == 0:\n",
    "                neg_cases.append((id, lab))\n",
    "            \n",
    "        # reduce the number of postitive cases\n",
    "        # pos_cases = pos_cases[:int(0.1*len(pos_cases))]\n",
    "        \n",
    "        num_pos_tr = int(len(pos_cases) * 0.8)\n",
    "        num_neg_tr = int(len(neg_cases) * 0.8)\n",
    "        self.train_data = pos_cases[:num_pos_tr] + neg_cases[:num_neg_tr]\n",
    "        self.val_data = pos_cases[num_pos_tr:] + neg_cases[num_neg_tr:]\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_data)\n",
    "        else:\n",
    "            return len(self.val_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            img_path, lab = self.train_data[idx]\n",
    "            img = io.imread('/fast/yangz16/glaucoma/archive/all_images/all_images/' + img_path)\n",
    "            img = img.astype(np.float32)\n",
    "            img = min_max_scale(img)\n",
    "            img = img.transpose(2, 0, 1)\n",
    "            img = torch.from_numpy(img)\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img_path, lab = self.val_data[idx]\n",
    "            img = io.imread('/fast/yangz16/glaucoma/archive/all_images/all_images/' + img_path)\n",
    "            img = img.astype(np.float32)\n",
    "            img = min_max_scale(img)\n",
    "            img = img.transpose(2, 0, 1)\n",
    "            img = torch.from_numpy(img)\n",
    "            img = self.transform(img)\n",
    "\n",
    "        lab = torch.tensor(lab, dtype=torch.float32)\n",
    "        return img, lab\n",
    "\n",
    "class GlauDatasetBalance(Dataset):\n",
    "    def __init__(self, is_train, transform=None):\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "        \n",
    "        csv_file = '/fast/yangz16/glaucoma/archive/path_specified_label_SIMPLIFIED.csv'\n",
    "        df = pd.read_csv(csv_file)\n",
    "        ids = df['Eye ID'].tolist()\n",
    "        labels = df['Final Label'].tolist()\n",
    "        ids = [_.split('/')[-1] for _ in ids]\n",
    "\n",
    "        pos_cases = []\n",
    "        neg_cases = []\n",
    "        for id, lab in zip(ids, labels):\n",
    "            if lab == 1:\n",
    "                pos_cases.append((id, lab))\n",
    "            elif lab == 0:\n",
    "                neg_cases.append((id, lab))\n",
    "\n",
    "        num_pos_tr = int(len(pos_cases) * 0.8)\n",
    "        num_neg_tr = int(len(neg_cases) * 0.8)\n",
    "        self.train_data = pos_cases[:num_pos_tr]\n",
    "        self.train_data_neg = neg_cases[:num_neg_tr]\n",
    "        self.val_data = pos_cases[num_pos_tr:] + neg_cases[num_neg_tr:]\n",
    "\n",
    "        # Oversample positive cases to the number of training samples\n",
    "        factor = num_neg_tr // num_pos_tr\n",
    "        residue = num_neg_tr % num_pos_tr\n",
    "        self.train_data = self.train_data * factor + self.train_data[:residue]\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.is_train:\n",
    "            return len(self.train_data)  # number of positive samples for training\n",
    "        else:\n",
    "            return len(self.val_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.is_train:\n",
    "            img_path, lab = self.train_data[idx]\n",
    "            img_path_n, lab_n = self.train_data_neg[idx]\n",
    "            \n",
    "            img = io.imread('/fast/yangz16/glaucoma/archive/all_images/all_images/' + img_path)\n",
    "            img = img.astype(np.float32)\n",
    "            img = min_max_scale(img)\n",
    "            img = img.transpose(2, 0, 1)\n",
    "            img = torch.from_numpy(img)\n",
    "            img = self.transform(img)\n",
    "            \n",
    "            img_n = io.imread('/fast/yangz16/glaucoma/archive/all_images/all_images/' + img_path_n)\n",
    "            img_n = img_n.astype(np.float32)\n",
    "            img_n = min_max_scale(img_n)\n",
    "            img_n = img_n.transpose(2, 0, 1)\n",
    "            img_n = torch.from_numpy(img_n)\n",
    "            img_n = self.transform(img_n)\n",
    "            \n",
    "            lab = torch.tensor(lab, dtype=torch.float32)\n",
    "            lab_n = torch.tensor(lab_n, dtype=torch.float32)\n",
    "            return img, img_n, lab, lab_n\n",
    "            \n",
    "        else:\n",
    "            img_path, lab = self.val_data[idx]\n",
    "            img = io.imread('/fast/yangz16/glaucoma/archive/all_images/all_images/' + img_path)\n",
    "            img = img.astype(np.float32)\n",
    "            img = min_max_scale(img)\n",
    "            img = img.transpose(2, 0, 1)\n",
    "            img = torch.from_numpy(img)\n",
    "            img = self.transform(img)\n",
    "            \n",
    "            lab = torch.tensor(lab, dtype=torch.float32)\n",
    "            return img, lab\n",
    "\n",
    "def min_max_scale(img):\n",
    "    min_val = img.min(axis=(0, 1))\n",
    "    max_val = img.max(axis=(0, 1))\n",
    "    img = (img - min_val)/(max_val-min_val+1e-8)\n",
    "    return img\n",
    "\n",
    "class ResNet50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = torch.hub.load(\"pytorch/vision\", \"resnet50\", weights=\"IMAGENET1K_V2\")\n",
    "        self.model.fc = nn.Linear(2048, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-17T21:35:43.035829300Z",
     "start_time": "2024-04-17T21:35:43.032837500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#device = xm.xla_device()\n",
    "print(device)\n",
    "\n",
    "# Set hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Balanced sampling\n",
    "is_balance = True\n",
    "\n",
    "# Initialize transformations for data augmentation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256), antialias=True),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation(degrees=45),\n",
    "    # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "    # transforms.CenterCrop(224),\n",
    "    # transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256, 256), antialias=True),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-17T12:12:13.161999Z",
     "iopub.execute_input": "2024-04-17T12:12:13.162874Z",
     "iopub.status.idle": "2024-04-17T12:12:13.192104Z",
     "shell.execute_reply.started": "2024-04-17T12:12:13.162832Z",
     "shell.execute_reply": "2024-04-17T12:12:13.191086Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T21:35:45.209511500Z",
     "start_time": "2024-04-17T21:35:45.204524600Z"
    }
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Load the ImageNet Object Localization Challenge dataset\n",
    "# train_dataset = torchvision.datasets.ImageFolder(\n",
    "#     root='/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train',\n",
    "#     transform=transform\n",
    "# )\n",
    "if is_balance:\n",
    "    train_dataset = GlauDatasetBalance(is_train=True, transform=transform)\n",
    "    val_dataset = GlauDatasetBalance(is_train=False, transform=transform_val)\n",
    "else:\n",
    "    train_dataset = GlauDataset(is_train=True, transform=transform)\n",
    "    val_dataset = GlauDataset(is_train=False, transform=transform_val)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load the ResNet model\n",
    "model = ResNet50()\n",
    "#model = ResNet34()\n",
    "# model = ResNet18()\n",
    "\n",
    "# Parallelize training across multiple GPUs\n",
    "# model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Set the model to run on the device\n",
    "model = model.to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-17T12:12:16.755225Z",
     "iopub.execute_input": "2024-04-17T12:12:16.755918Z",
     "iopub.status.idle": "2024-04-17T12:12:20.238262Z",
     "shell.execute_reply.started": "2024-04-17T12:12:16.755883Z",
     "shell.execute_reply": "2024-04-17T12:12:20.237144Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T21:35:51.490893800Z",
     "start_time": "2024-04-17T21:35:48.180565100Z"
    }
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yangz16/.cache/torch/hub/pytorch_vision_main\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=num_epochs, power=1.0)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-17T12:12:22.874596Z",
     "iopub.execute_input": "2024-04-17T12:12:22.875321Z",
     "iopub.status.idle": "2024-04-17T12:12:22.881677Z",
     "shell.execute_reply.started": "2024-04-17T12:12:22.875286Z",
     "shell.execute_reply": "2024-04-17T12:12:22.880734Z"
    },
    "trusted": true,
    "ExecuteTime": {
     "end_time": "2024-04-17T21:35:53.343070900Z",
     "start_time": "2024-04-17T21:35:53.331103200Z"
    }
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model...\n",
    "for epoch in range(num_epochs):\n",
    "    # Metric\n",
    "    metric = torchmetrics.classification.BinaryAUROC()\n",
    "    metric_acc = torchmetrics.classification.BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "    metric_acc.to(device)\n",
    "    log_loss = 0\n",
    "    num_it = 0\n",
    "    for samps in train_loader:\n",
    "        if is_balance:\n",
    "            inputs = torch.cat((samps[0], samps[1]), dim=0)\n",
    "            labels = torch.cat((samps[2], samps[3]), dim=0)\n",
    "        else:\n",
    "            inputs = samps[0]\n",
    "            labels = samps[1]\n",
    "        \n",
    "        # Move input and label tensors to the device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Zero out the optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Log loss\n",
    "        log_loss += loss.item()\n",
    "        num_it += 1\n",
    "\n",
    "        metric.update(outputs, labels)\n",
    "        metric_acc.update(outputs, labels)\n",
    "\n",
    "    scheduler.step()\n",
    "    for param_group in optimizer.param_groups:\n",
    "        current_lr = param_group['lr']\n",
    "\n",
    "    auroc = metric.compute()\n",
    "    acc = metric_acc.compute()\n",
    "\n",
    "    # Print the loss for every epoch\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Avg loss: {log_loss/num_it:.4f}, LR: {current_lr:.6f}, AUROC: {auroc:.4f}, Acc: {acc:.4f}')\n",
    "\n",
    "\n",
    "    metric = torchmetrics.classification.BinaryAUROC()\n",
    "    metric_acc = torchmetrics.classification.BinaryAccuracy()\n",
    "    metric.to(device)\n",
    "    metric_acc.to(device)\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            metric.update(outputs, labels)\n",
    "            metric_acc.update(outputs, labels)\n",
    "\n",
    "    auroc = metric.compute()\n",
    "    acc = metric_acc.compute()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, AUROC: {auroc:.4f}, Acc: {acc:.4f}')\n",
    "\n",
    "print(f'Finished Training, Loss: {loss.item():.4f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-17T12:12:26.038863Z",
     "iopub.execute_input": "2024-04-17T12:12:26.039237Z",
     "iopub.status.idle": "2024-04-17T15:45:11.449699Z",
     "shell.execute_reply.started": "2024-04-17T12:12:26.039206Z",
     "shell.execute_reply": "2024-04-17T15:45:11.448550Z"
    },
    "trusted": true,
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(model, '/kaggle/working/all_images_trained_model.pt')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-17T15:45:47.641674Z",
     "iopub.execute_input": "2024-04-17T15:45:47.642672Z",
     "iopub.status.idle": "2024-04-17T15:45:47.827542Z",
     "shell.execute_reply.started": "2024-04-17T15:45:47.642626Z",
     "shell.execute_reply": "2024-04-17T15:45:47.826472Z"
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": []
  }
 ]
}
