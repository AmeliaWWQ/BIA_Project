{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8074461,"sourceType":"datasetVersion","datasetId":4764891},{"sourceId":8084878,"sourceType":"datasetVersion","datasetId":4772419},{"sourceId":8140896,"sourceType":"datasetVersion","datasetId":4809939}],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from skimage import io\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\nimport torchmetrics\n\n\nclass GlauDataset(Dataset):\n    def __init__(self, is_train, transform=None):\n        self.is_train = is_train\n        self.transform = transform\n        \n        csv_file = '/kaggle/input/all-images/path_specified_label_SIMPLIFIED.csv'\n        df = pd.read_csv(csv_file)\n        ids = df['Eye ID'].tolist()\n        labels = df['Final Label'].tolist()\n        ids = [_.split('/')[-1] for _ in ids]\n\n        pos_cases = []\n        neg_cases = []\n        for id, lab in zip(ids, labels):\n            if lab == 1:\n                pos_cases.append((id, lab))\n            elif lab == 0:\n                neg_cases.append((id, lab))\n\n        num_pos_tr = int(len(pos_cases) * 0.8)\n        num_neg_tr = int(len(neg_cases) * 0.8)\n        self.train_data = pos_cases[:num_pos_tr] + neg_cases[:num_neg_tr]\n        self.val_data = pos_cases[num_pos_tr:] + neg_cases[num_neg_tr:]\n\n    def __len__(self):\n        if self.is_train:\n            return len(self.train_data)\n        else:\n            return len(self.val_data)\n\n    def __getitem__(self, idx):\n        if self.is_train:\n            img_path, lab = self.train_data[idx]\n            img = io.imread('/kaggle/input/all-images/all_images/all_images/' + img_path)\n            img = img.astype(np.float32)\n            img = min_max_scale(img)\n            img = img.transpose(2, 0, 1)\n            img = torch.from_numpy(img)\n            img = self.transform(img)\n        else:\n            img_path, lab = self.val_data[idx]\n            img = io.imread('/kaggle/input/all-images/all_images/all_images/' + img_path)\n            img = img.astype(np.float32)\n            img = img.transpose(2, 0, 1)\n            img = torch.from_numpy(img)\n\n        lab = torch.tensor(lab, dtype=torch.float32)\n        return img, lab\n\ndef min_max_scale(img):\n    min_val = img.min(axis=(0, 1))\n    max_val = img.max(axis=(0, 1))\n    img = (img - min_val)/(max_val-min_val+1e-8)\n    return img\n\nclass ResNet50(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = torch.hub.load(\"pytorch/vision\", \"resnet50\", weights=\"IMAGENET1K_V2\")\n        self.model.fc = nn.Linear(2048, 1)\n\n    def forward(self, x):\n        return self.model(x).squeeze()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-17T12:12:01.040341Z","iopub.execute_input":"2024-04-17T12:12:01.040603Z","iopub.status.idle":"2024-04-17T12:12:10.736442Z","shell.execute_reply.started":"2024-04-17T12:12:01.040580Z","shell.execute_reply":"2024-04-17T12:12:10.735485Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n#device = xm.xla_device()\nprint(device)\n\n# Set hyperparameters\nnum_epochs = 10\nbatch_size = 128\nlearning_rate = 0.0001\n\n# Initialize transformations for data augmentation\ntransform = transforms.Compose([\n    transforms.Resize((256, 256), antialias=True),\n    transforms.RandomHorizontalFlip(),\n    # transforms.RandomVerticalFlip(),\n    # transforms.RandomRotation(degrees=45),\n    # transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n    # transforms.CenterCrop(224),\n    # transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:12:13.161999Z","iopub.execute_input":"2024-04-17T12:12:13.162874Z","iopub.status.idle":"2024-04-17T12:12:13.192104Z","shell.execute_reply.started":"2024-04-17T12:12:13.162832Z","shell.execute_reply":"2024-04-17T12:12:13.191086Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the ImageNet Object Localization Challenge dataset\n# train_dataset = torchvision.datasets.ImageFolder(\n#     root='/kaggle/input/imagenet-object-localization-challenge/ILSVRC/Data/CLS-LOC/train',\n#     transform=transform\n# )\ntrain_dataset = GlauDataset(is_train=True, transform=transform)\nval_dataset = GlauDataset(is_train=False)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\n# Load the ResNet model\nmodel = ResNet50()\n#model = ResNet34()\n# model = ResNet18()\n\n# Parallelize training across multiple GPUs\n# model = torch.nn.DataParallel(model)\n\n# Set the model to run on the device\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:12:16.755225Z","iopub.execute_input":"2024-04-17T12:12:16.755918Z","iopub.status.idle":"2024-04-17T12:12:20.238262Z","shell.execute_reply.started":"2024-04-17T12:12:16.755883Z","shell.execute_reply":"2024-04-17T12:12:20.237144Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/pytorch/vision/zipball/main\" to /root/.cache/torch/hub/main.zip\nDownloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 167MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the loss function and optimizer\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=num_epochs, power=1.0)","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:12:22.874596Z","iopub.execute_input":"2024-04-17T12:12:22.875321Z","iopub.status.idle":"2024-04-17T12:12:22.881677Z","shell.execute_reply.started":"2024-04-17T12:12:22.875286Z","shell.execute_reply":"2024-04-17T12:12:22.880734Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Train the model...\nfor epoch in range(num_epochs):\n    # Metric\n    metric = torchmetrics.classification.BinaryAUROC()\n    metric_acc = torchmetrics.classification.BinaryAccuracy()\n    metric.to(device)\n    metric_acc.to(device)\n    for inputs, labels in train_loader:\n        # Move input and label tensors to the device\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        # Zero out the optimizer\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass\n        loss.backward()\n        optimizer.step()\n\n        metric.update(outputs, labels)\n        metric_acc.update(outputs, labels)\n\n    scheduler.step()\n    for param_group in optimizer.param_groups:\n        current_lr = param_group['lr']\n\n    auroc = metric.compute()\n    acc = metric_acc.compute()\n\n    # Print the loss for every epoch\n    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}, LR: {current_lr:.6f}, AUROC: {auroc:.4f}, Acc: {acc:.4f}')\n\n\n    metric = torchmetrics.classification.BinaryAUROC()\n    metric_acc = torchmetrics.classification.BinaryAccuracy()\n    metric.to(device)\n    metric_acc.to(device)\n    for inputs, labels in val_loader:\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        with torch.no_grad():\n            outputs = model(inputs)\n            metric.update(outputs, labels)\n            metric_acc.update(outputs, labels)\n\n    auroc = metric.compute()\n    acc = metric_acc.compute()\n\n    print(f'Epoch {epoch+1}/{num_epochs}, AUROC: {auroc:.4f}, Acc: {acc:.4f}')\n\nprint(f'Finished Training, Loss: {loss.item():.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T12:12:26.038863Z","iopub.execute_input":"2024-04-17T12:12:26.039237Z","iopub.status.idle":"2024-04-17T15:45:11.449699Z","shell.execute_reply.started":"2024-04-17T12:12:26.039206Z","shell.execute_reply":"2024-04-17T15:45:11.448550Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Epoch 1/10, Loss: 11.1240, LR: 0.000090, AUROC: 0.6705, Acc: 0.8185\nEpoch 1/10, AUROC: 0.5063, Acc: 0.8658\nEpoch 2/10, Loss: 23.0343, LR: 0.000080, AUROC: 0.7302, Acc: 0.8369\nEpoch 2/10, AUROC: 0.5012, Acc: 0.8701\nEpoch 3/10, Loss: 20.5066, LR: 0.000070, AUROC: 0.7746, Acc: 0.8679\nEpoch 3/10, AUROC: 0.4945, Acc: 0.8867\nEpoch 4/10, Loss: 14.0011, LR: 0.000060, AUROC: 0.8300, Acc: 0.9103\nEpoch 4/10, AUROC: 0.5029, Acc: 0.9321\nEpoch 5/10, Loss: 18.3105, LR: 0.000050, AUROC: 0.8983, Acc: 0.9498\nEpoch 5/10, AUROC: 0.4938, Acc: 0.9657\nEpoch 6/10, Loss: 8.1725, LR: 0.000040, AUROC: 0.9586, Acc: 0.9703\nEpoch 6/10, AUROC: 0.4993, Acc: 0.9672\nEpoch 7/10, Loss: 4.7423, LR: 0.000030, AUROC: 0.9842, Acc: 0.9841\nEpoch 7/10, AUROC: 0.4999, Acc: 0.9674\nEpoch 8/10, Loss: 0.8834, LR: 0.000020, AUROC: 0.9923, Acc: 0.9917\nEpoch 8/10, AUROC: 0.5000, Acc: 0.9675\nEpoch 9/10, Loss: 8.4236, LR: 0.000010, AUROC: 0.9972, Acc: 0.9948\nEpoch 9/10, AUROC: 0.4993, Acc: 0.9678\nEpoch 10/10, Loss: 0.1041, LR: 0.000000, AUROC: 0.9987, Acc: 0.9974\nEpoch 10/10, AUROC: 0.4971, Acc: 0.9678\nFinished Training, Loss: 0.1041\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/all_images_trained_model.pt')","metadata":{"execution":{"iopub.status.busy":"2024-04-17T15:45:47.641674Z","iopub.execute_input":"2024-04-17T15:45:47.642672Z","iopub.status.idle":"2024-04-17T15:45:47.827542Z","shell.execute_reply.started":"2024-04-17T15:45:47.642626Z","shell.execute_reply":"2024-04-17T15:45:47.826472Z"},"trusted":true},"execution_count":6,"outputs":[]}]}